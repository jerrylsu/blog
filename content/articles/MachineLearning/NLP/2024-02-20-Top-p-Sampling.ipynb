{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "425e610d-b585-4781-909a-4f956a000a2a",
   "metadata": {},
   "source": [
    "date: 2024-02-20 11:17:17\n",
    "author: Jerry Su\n",
    "slug: Nucleus Sampling Top-p Sampling\n",
    "title: Nucleus Sampling Top-p Sampling\n",
    "category: \n",
    "tags: LLM, NLP\n",
    "toc: show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a8f6e2-b192-4fc4-b47b-eeadf85ac617",
   "metadata": {},
   "source": [
    "### 1. 温度调节（Temperature Scaling）\n",
    "\n",
    "- 为了调整概率分布的“锐利度”，可以引入一个温度参数（Temperature）。温度较高时，概率分布变得更加平坦，增加了低概率单词被选中的机会；温度较低时，概率分布变得更尖锐，高概率单词被选中的机会增加。\n",
    "\n",
    "- 温度调节是通过将概率分布中的每个概率值除以温度参数，然后对结果应用softmax函数来实现的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c8d570-a071-4390-b7a0-94b9208859e8",
   "metadata": {},
   "source": [
    "### 2. 核采样（Nucleus Sampling，Top-p Sampling）\n",
    "\n",
    "- 核采样是一种更高级的采样策略，它选择累积概率超过某个阈值p的最小单词集。这允许模型动态调整采样的单词数量，基于当前上下文的不确定性。\n",
    "\n",
    "- 与Top-K采样相比，核采样可以自适应地调整考虑的词汇范围，避免过多地限制或放宽选择。\n",
    "\n",
    "**核采样原理**\n",
    "\n",
    "- 核采样的关键思想是从词汇分布中选择一个词汇子集，使得这个子集中词汇的累积概率接近但不超过一个预先定义的阈值p（0 < p < 1）。这个子集被称为“核”（nucleus），只有这个核中的词汇会被考虑用于下一步的随机采样。这样，生成的文本既不会过于随机（因为避免了极低概率词的干扰），也不会过于确定性（因为没有限制为前K个最高概率的词）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4212b6d6-dd45-4ed3-a04f-65adb98f6837",
   "metadata": {},
   "source": [
    "### 3. 累计概率\n",
    "\n",
    "累积概率的计算是在处理概率分布时的一个关键步骤，尤其是在执行如核采样（Top-p Sampling）这样的任务时。累积概率为我们提供了一个方式，来确定随机事件发生的概率范围。在核采样中，它帮助我们决定哪些词汇（单词）的集合应该被考虑进来，以确保这个集合覆盖了预定比例\\(p\\)的概率总和。这里是累积概率计算的具体步骤：\n",
    "\n",
    "- 步骤1：获取概率分布\n",
    "首先，你需要有一个概率分布，这通常是模型对下一个单词的预测概率。假设我们有一个词汇表，模型为每个可能的下一个单词提供了一个概率。\n",
    "\n",
    "- 步骤2：排序\n",
    "将概率分布按照概率值从高到低进行排序。这样，最高概率的单词会放在列表的最前面。\n",
    "\n",
    "- 步骤3：计算累积概率\n",
    "接下来，计算排序后的概率列表的累积概率。累积概率是指从列表的开始到当前位置的所有概率值的总和。对于列表中的第\\(i\\)个单词，其累积概率可以表示为：\n",
    "\n",
    "$CumulativeProbability(i) = \\sum_{k=1}^{i} Probability(k)$\n",
    "\n",
    "其中，\\(Probability(k)\\)是第\\(k\\)个单词的概率。\n",
    "\n",
    "- 步骤4：确定阈值\\(p\\)的覆盖\n",
    "确定满足累积概率小于或等于阈值\\(p\\)的最大集合。也就是说，你需要找到一个最小的\\(i\\)，使得：\n",
    "\n",
    "$CumulativeProbability(i) \\geq p$\n",
    "\n",
    "这意味着，从排序后的列表中取出前\\(i\\)个单词，这些单词的累积概率总和将至少覆盖阈值\\(p\\)指定的概率质量。\n",
    "\n",
    "- 示例\n",
    "假设我们的模型预测下一个单词的概率分布如下（已排序）：\n",
    "\n",
    "- 单词A：0.3\n",
    "- 单词B：0.2\n",
    "- 单词C：0.15\n",
    "- 单词D：0.1\n",
    "- 单词E及之后的其他单词：小于0.1的概率\n",
    "\n",
    "如果我们设置阈值\\(p=0.6\\)，那么：\n",
    "\n",
    "- 累积到单词A：0.3\n",
    "- 累积到单词B：0.5 (0.3 + 0.2)\n",
    "- 累积到单词C：0.65 (0.3 + 0.2 + 0.15)\n",
    "\n",
    "因此，为了确保累积概率超过0.6，我们需要选择单词A、B、C作为考虑的词汇范围。\n",
    "\n",
    "通过这种方式，核采样算法确保在生成下一个单词时，考虑了概率分布中最重要的部分，同时保持了一定程度的随机性和多样性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37d39e26-e047-4d1e-9d81-21e714e9f2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.\n",
      "[NbConvertApp] Converting notebook 2024-02-20-Top-p-Sampling.ipynb to markdown\n",
      "[NbConvertApp] Writing 1980 bytes to 2024-02-20-Top-p-Sampling.md\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to markdown 2024-02-20-Top-p-Sampling.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69aa950-7c0a-4396-bbc8-2a5fdbb519c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
