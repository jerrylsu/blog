{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "date: 2022-05-02 11:17:17\n",
    "author: Jerry Su\n",
    "slug: pytorch.nn.functional.pad\n",
    "title: pytorch.nn.functional.pad\n",
    "category: \n",
    "tags: Pytorch, Paddle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch\n",
    "\n",
    "[torch.nn.functional.pad](https://pytorch.org/docs/stable/generated/torch.nn.functional.pad.html#torch.nn.functional.pad)\n",
    "\n",
    "从输入input的最后一个维度向前padding\n",
    "\n",
    "输入input的$\\left\\lfloor\\frac{\\text{len(pad)}}{2}\\right\\rfloor$个维度进行padding\n",
    "\n",
    "- 如果只padding输入张量input的最后1个维度，pad的形式如：(padding_left, padding_right)\n",
    "\n",
    "- 如果只padding输入张量input的最后2个维度，pad的形式如：(padding_left, padding_right, padding_top, padding_bottom)\n",
    "\n",
    "- 如果只padding输入张量input的最后3个维度，pad的形式如：(padding_left, padding_right, padding_top, padding_bottom, padding_front, padding_back)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_len = 94\n",
    "pad_token_id = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4维度输入张量: (3, 3, 4, 2)维度\n",
    "t4d = torch.empty(3, 3, 4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 4, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding最后1维\n",
    "# padding数是左右各1个\n",
    "p1d = (1, 1) # (padding_left, padding_right)\n",
    "out = torch.nn.functional.pad(t4d, pad=p1d, mode=\"constant\", value=0)\n",
    "out.size()  # (3, 3, 4, 2) -> (3, 3, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 8, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding最后2维。\n",
    "# 倒数第1维度：padding数是左右各1个；\n",
    "# 倒数第2维度：padding数是上下各2个。 \n",
    "p2d = (1, 1, 2, 2) # pad last dim by (1, 1) and 2nd to last by (2, 2)\n",
    "out = torch.nn.functional.pad(t4d, p2d, \"constant\", 0)\n",
    "out.size()  # (3, 3, 4, 2) -> (3, 3, 8, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 9, 7, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding最后3维。\n",
    "# 倒数第1维度：padding数是左0右1；\n",
    "# 倒数第2维度：padding数是上2下1；\n",
    "# 倒数第3维度：padding数是上3下3。 \n",
    "p3d = (0, 1, 2, 1, 3, 3) # pad by (0, 1), (2, 1), and (3, 3)\n",
    "out = torch.nn.functional.pad(t4d, p3d, \"constant\", 0)\n",
    "out.size() # (3, 3, 4, 2) -> (3, 9, 7, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4002])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.4822e+11, 4.8617e+30, 1.9069e-19,  ..., 1.8037e+28, 1.9368e+31,\n",
       "         3.1387e-11]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = torch.empty((1, 4002))\n",
    "print(input_ids.shape)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4096])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4822e+11,  4.8617e+30,  1.9069e-19,  ..., -1.0000e+02,\n",
       "         -1.0000e+02, -1.0000e+02]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = torch.nn.functional.pad(input_ids, (0, padding_len), value=pad_token_id)\n",
    "print(input_ids.shape)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### paddle\n",
    "\n",
    "[paddle.nn.functional.pad](https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/functional/pad_cn.html)\n",
    "\n",
    "如果 mode 为 'constant'，并且 pad 的长度为 x 维度的2倍时， 则会根据 pad 和 value 对 x 从前面的维度向后依次补齐；\n",
    "\n",
    "否则：\n",
    "\n",
    "- 当输入维度为3时，pad的格式为[pad_left, pad_right]； \n",
    "\n",
    "- 当输入维度为4时，pad的格式为[pad_left, pad_right, pad_top, pad_bottom]； \n",
    "\n",
    "- 当输入维度为5时，pad的格式为[pad_left, pad_right, pad_top, pad_bottom, pad_front, pad_back]。\n",
    "\n",
    "**⚠️注意**：与torch的区别，paddle是从前往后padding，所以一般需要pad=(0, 0, ...)补齐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[1, 1, 3], dtype=float32, place=CPUPlace, stop_gradient=True,\n",
       "       [[[1., 2., 3.]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_shape = (1, 1, 3)\n",
    "x3d = paddle.arange(np.prod(x_shape), dtype=\"float32\").reshape(x_shape) + 1\n",
    "x3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[1, 1, 8], dtype=float32, place=CPUPlace, stop_gradient=True,\n",
       "       [[[1., 1., 1., 2., 3., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_paddle = paddle.nn.functional.pad(x3d, [0, 0, 0, 0, 2, 3], value=1, mode='constant')\n",
    "out_paddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "input tensor dimension is 3, it's data format should be in ['NCL', 'NLC'] but got NCHW",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22733/2557938510.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout_paddle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'constant'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mout_paddle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/blog/lib/python3.8/site-packages/paddle/nn/functional/common.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(x, pad, mode, value, data_format, name)\u001b[0m\n\u001b[1;32m   1288\u001b[0m         \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"NCDHW\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"NDHWC\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m     }\n\u001b[0;32m-> 1290\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msupported_format_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1291\u001b[0m     \"input tensor dimension is {}, it's data format should be in {} but got {}\".format(\n\u001b[1;32m   1292\u001b[0m         x_dim, supported_format_map[x_dim], data_format)\n",
      "\u001b[0;31mAssertionError\u001b[0m: input tensor dimension is 3, it's data format should be in ['NCL', 'NLC'] but got NCHW"
     ]
    }
   ],
   "source": [
    "out_paddle = paddle.nn.functional.pad(x3d, [2, 3], value=1, mode='constant')\n",
    "out_paddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[1, 1, 8], dtype=float32, place=CPUPlace, stop_gradient=True,\n",
       "       [[[1., 1., 1., 2., 3., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_paddle = paddle.nn.functional.pad(x3d, [2, 3], value=1, mode='constant', data_format='NCL')\n",
    "out_paddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[1, 4002], dtype=float32, place=CPUPlace, stop_gradient=True,\n",
       "       [[1.   , 2.   , 3.   , ..., 4000., 4001., 4002.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_shape = (1, 4002)\n",
    "x2d = paddle.arange(np.prod(x_shape), dtype=\"float32\").reshape(x_shape) + 1\n",
    "x2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[1, 4096], dtype=float32, place=CPUPlace, stop_gradient=True,\n",
       "       [[ 1.  ,  2.  ,  3.  , ..., -100., -100., -100.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_paddle = paddle.nn.functional.pad(x2d, [0, 0, 0, padding_len], value=pad_token_id, mode='constant')\n",
    "out_paddle"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:blog]",
   "language": "python",
   "name": "conda-env-blog-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
