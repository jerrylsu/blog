{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "date: 2021-01-05 12:17:17\n",
    "author: Jerry Su\n",
    "slug: Python-dataclasses\n",
    "title: Python dataclasses\n",
    "category: \n",
    "tags: Python\n",
    "summary: Reason is the light and the light of life.\n",
    "toc: show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field, asdict, astuple\n",
    "import dataclasses\n",
    "from typing import List, Optional, Union, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[why dataclasses](https://zhuanlan.zhihu.com/p/34963159?utm_source=wechatMessage_article_bottom)\n",
    "\n",
    "[https://docs.python.org/zh-cn/3/library/dataclasses.html](https://docs.python.org/zh-cn/3/library/dataclasses.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- field 被定义为具有类型标注的类变量。\n",
    "\n",
    "```\n",
    "Signature:\n",
    "field(\n",
    "    *,\n",
    "    default=<dataclasses._MISSING_TYPE object at 0x7f60fc21b7f0>,\n",
    "    default_factory=<dataclasses._MISSING_TYPE object at 0x7f60fc21b7f0>,\n",
    "    init=True,\n",
    "    repr=True,\n",
    "    hash=None,\n",
    "    compare=True,\n",
    "    metadata=None,\n",
    ")\n",
    "Docstring:\n",
    "Return an object to identify dataclass fields.\n",
    "\n",
    "default is the default value of the field.  default_factory is a\n",
    "0-argument function called to initialize a field's value.  If init\n",
    "is True, the field will be a parameter to the class's __init__()\n",
    "function.  If repr is True, the field will be included in the\n",
    "object's repr().  If hash is True, the field will be included in\n",
    "the object's hash().  If compare is True, the field will be used\n",
    "in comparison functions.  metadata, if specified, must be a\n",
    "mapping which is stored but not otherwise examined by dataclass.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataTrainingArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
    "    \"\"\"\n",
    "\n",
    "    dataset_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"The name of the dataset to use (via the datasets library).\"}\n",
    "    )\n",
    "    dataset_config_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"The configuration name of the dataset to use (via the datasets library).\"}\n",
    "    )\n",
    "    train_file: Optional[str] = field(default=None, metadata={\"help\": \"The input training data file (a text file).\"})\n",
    "    validation_file: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"An optional input evaluation data file to evaluate the perplexity on (a text file).\"},\n",
    "    )\n",
    "    train_ref_file: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"An optional input train ref data file for whole word masking in Chinese.\"},\n",
    "    )\n",
    "    validation_ref_file: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"An optional input validation ref data file for whole word masking in Chinese.\"},\n",
    "    )\n",
    "    overwrite_cache: bool = field(\n",
    "        default=False, metadata={\"help\": \"Overwrite the cached training and evaluation sets\"}\n",
    "    )\n",
    "    validation_split_percentage: Optional[int] = field(\n",
    "        default=5,\n",
    "        metadata={\n",
    "            \"help\": \"The percentage of the train set used as validation set in case there's no validation split\"\n",
    "        },\n",
    "    )\n",
    "    max_seq_length: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"The maximum total input sequence length after tokenization. Sequences longer \"\n",
    "            \"than this will be truncated. Default to the max input length of the model.\"\n",
    "        },\n",
    "    )\n",
    "    preprocessing_num_workers: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"The number of processes to use for the preprocessing.\"},\n",
    "    )\n",
    "    mlm_probability: float = field(\n",
    "        default=0.15, metadata={\"help\": \"Ratio of tokens to mask for masked language modeling loss\"}\n",
    "    )\n",
    "    pad_to_max_length: bool = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": \"Whether to pad all samples to `max_seq_length`. \"\n",
    "            \"If False, will pad the samples dynamically when batching to the maximum length in the batch.\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.train_file is not None:\n",
    "            extension = self.train_file.split(\".\")[-1]\n",
    "            assert extension in [\"csv\", \"json\", \"txt\"], \"`train_file` should be a csv, a json or a txt file.\"\n",
    "        if self.validation_file is not None:\n",
    "            extension = self.validation_file.split(\".\")[-1]\n",
    "            assert extension in [\"csv\", \"json\", \"txt\"], \"`validation_file` should be a csv, a json or a txt file.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataTrainingArguments(dataset_name=None, dataset_config_name=None, train_file=None, validation_file=None, train_ref_file=None, validation_ref_file=None, overwrite_cache=False, validation_split_percentage=5, max_seq_length=None, preprocessing_num_workers=None, mlm_probability=0.15, pad_to_max_length=False)\n"
     ]
    }
   ],
   "source": [
    "args = DataTrainingArguments()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.mlm_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_name': None,\n",
       " 'dataset_config_name': None,\n",
       " 'train_file': None,\n",
       " 'validation_file': None,\n",
       " 'train_ref_file': None,\n",
       " 'validation_ref_file': None,\n",
       " 'overwrite_cache': False,\n",
       " 'validation_split_percentage': 5,\n",
       " 'max_seq_length': None,\n",
       " 'preprocessing_num_workers': None,\n",
       " 'mlm_probability': 0.15,\n",
       " 'pad_to_max_length': False}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asdict(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None, None, False, 5, None, None, 0.15, False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "astuple(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_name': None,\n",
       " 'dataset_config_name': None,\n",
       " 'train_file': None,\n",
       " 'validation_file': None,\n",
       " 'train_ref_file': None,\n",
       " 'validation_ref_file': None,\n",
       " 'overwrite_cache': False,\n",
       " 'validation_split_percentage': 5,\n",
       " 'max_seq_length': None,\n",
       " 'preprocessing_num_workers': None,\n",
       " 'mlm_probability': 0.15,\n",
       " 'pad_to_max_length': False}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8124, 0.5449, 0.5745, 0.1047, 0.7168],\n",
       "        [0.9950, 0.3831, 0.8726, 0.6776, 0.0495],\n",
       "        [0.2290, 0.1355, 0.6567, 0.5525, 0.6538]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.rand([3, 5])\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.new_full([3, 6], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs[0].new_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:blog] *",
   "language": "python",
   "name": "conda-env-blog-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
