Status: published
Date: 2019-06-22 04:40:15
Author: Jerry Su
Slug: Bias-vs-Variance
Title: Bias vs Variance
Category: 
Tags: Machine Learning
summary: Reason is the light and the light of life.
toc: show

### 方差与偏差

泛化误差分为：偏差和方差

偏差：指算法的期望预测值与真实值之间的偏差程度，反应的是模型本身拟合能力。(单模型)

方差：度量了同等大小数据集的变动导致学习性能的变化，刻画数据扰动所导致的影响。(多模型)

当模型越复杂时，训练数据的拟合程度就越高，模型的训练偏差就越小。但如果还一组数据可能模型的变化就很大，即模型的方差很大。所以复杂度高的模型容易产生过拟合。

当模型简单时，即使还一组训练数据，得出的学习器之间差别不是很大，即模型的方差较小。但由于模型简单，所以存在比较大的偏差。

所以，在训练一个模型时，需要平衡好方差和偏差。

### 为什么RF的树深一般大于GBDT树的深度？

对于Bagging算法，由于时并行的训练若干个弱学习器，他们之间相互独立，主要目的降低方差。所以为了平衡好方差与偏差，每一个弱学习器目标便是如何降低偏差，因而会采用复杂度高的模型作为弱学习器，例如深度较深甚至不剪枝的树，神经网络等。

对于Boosting算法，训练的弱学习器都是在上一轮基础上更加的拟合数据，保证的是模型的偏差。所以为了平衡好方差与偏差，每一个弱学习器目标便是如何降低弱学习器之间的方差，因而会采用复杂度低的模型作为弱学习器，例如深度很浅的树。
